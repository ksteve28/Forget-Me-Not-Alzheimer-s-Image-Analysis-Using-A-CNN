{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "appreciated-executive",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "# try:\n",
    "#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "#     print('Device:', tpu.master())\n",
    "#     tf.config.experimental_connect_to_cluster(tpu)\n",
    "#     tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "#     strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "# except:\n",
    "#     strategy = tf.distribute.get_strategy()\n",
    "# print('Number of replicas:', strategy.num_replicas_in_sync)\n",
    "    \n",
    "# print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "# BATCH_SIZE = 32 * strategy.num_replicas_in_sync\n",
    "# IMAGE_SIZE = [176, 208]\n",
    "# EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-north",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "corporate-first",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "image_size = [64, 64]\n",
    "batch_size = 32\n",
    "epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reserved-visitor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2612 files belonging to 2 classes.\n",
      "Using 2090 files for training.\n",
      "Found 2612 files belonging to 2 classes.\n",
      "Using 522 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '../Alz_data/train/',\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    color_mode='grayscale',\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "val_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '../Alz_data/train',\n",
    "        validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    color_mode='grayscale',\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['ModerateDementia', 'NonDementia']\n",
    "train_data.class_names = class_names\n",
    "val_data.class_names = class_names\n",
    "\n",
    "NUM_CLASSES = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_data.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(train_data.class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_hot_label(image, label):\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    return image, label\n",
    "\n",
    "train_data = train_data.map(one_hot_label, num_parallel_calls=AUTOTUNE)\n",
    "val_data = val_data.map(one_hot_label, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-legend",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-watch",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_data = val_data.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(filters):\n",
    "    block = tf.keras.Sequential([\n",
    "        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPool2D()\n",
    "    ]\n",
    "    )\n",
    "    \n",
    "    return block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-trustee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_block(units, dropout_rate):\n",
    "    block = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "        tf.keras.Input(shape=(*image_size, 3)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(16, 3, activation='sigmoid', padding='same'),\n",
    "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPool2D(),\n",
    "        \n",
    "        conv_block(32),\n",
    "        conv_block(64),\n",
    "        \n",
    "        conv_block(128),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        conv_block(256),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        dense_block(512, 0.7),\n",
    "        dense_block(128, 0.5),\n",
    "        dense_block(64, 0.3),\n",
    "        \n",
    "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with strategy.scope():\n",
    "model = build_model()\n",
    "\n",
    "METRICS = [tf.keras.metrics.AUC(name='auc')]\n",
    "    \n",
    "model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.losses.CategoricalCrossentropy(),\n",
    "        metrics=METRICS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1 **(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(0.01, 20)\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"alzheimer_model.h5\",\n",
    "                                                    save_best_only=True)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                     restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "#     callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler],\n",
    "    epochs=epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['auc']\n",
    "val_acc = history.history['val_auc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_auc']\n",
    "\n",
    "epochs_range = range(epoch)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_standarization = model.fit(\n",
    "#     train_data,\n",
    "#     validation_data=val_data,\n",
    "# #     callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler],\n",
    "#     epochs=epoch\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-remedy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '../Alzheimer_s Dataset/test/',\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "test_data = test_data.map(one_hot_label, num_parallel_calls=AUTOTUNE)\n",
    "test_data = test_data.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-giving",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Categorical Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_2():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "        tf.keras.Input(shape=(*image_size, 3)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPool2D(),\n",
    "        \n",
    "        conv_block(32),\n",
    "        conv_block(64),\n",
    "        \n",
    "        conv_block(128),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        conv_block(256),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        dense_block(512, 0.7),\n",
    "        dense_block(128, 0.5),\n",
    "        dense_block(64, 0.3),\n",
    "        \n",
    "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modeling = build_model_2()\n",
    "\n",
    "METRICS = [tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy')]\n",
    "    \n",
    "modeling.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.losses.CategoricalCrossentropy(),\n",
    "        metrics=METRICS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1 **(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(0.1, 40)\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"alzheimer_model.h5\",\n",
    "                                                    save_best_only=True)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                     restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = modeling.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "#     callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler],\n",
    "    epochs=epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_categorical_accuracy']\n",
    "\n",
    "epochs_range = range(epoch)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-strike",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-athletics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "        tf.keras.Input(shape=(*image_size, 3)),\n",
    "        \n",
    "                \n",
    "        tf.keras.layers.Flatten(),\n",
    "        dense_block(512, 0.7),\n",
    "        dense_block(128, 0.5),\n",
    "        dense_block(64, 0.3),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPool2D(),\n",
    "        \n",
    "        conv_block(32),\n",
    "        conv_block(64),\n",
    "        \n",
    "        conv_block(128),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        conv_block(256),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "        \n",
    "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-simpson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modeling = build_model()\n",
    "\n",
    "METRICS = [tf.keras.metrics.Accuracy(name='accuracy')]\n",
    "    \n",
    "modeling.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.losses.CategoricalCrossentropy(),\n",
    "        metrics=METRICS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1 **(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(0.01, 20)\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"alzheimer_model.h5\",\n",
    "                                                    save_best_only=True)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                     restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = modeling.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler],\n",
    "    epochs=epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_accuracy']\n",
    "\n",
    "epochs_range = range(epoch)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-listening",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-plumbing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling = build_model()\n",
    "\n",
    "METRICS = [tf.keras.metrics.Precision(name='precision')]\n",
    "    \n",
    "modeling.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.losses.CategoricalCrossentropy(),\n",
    "        metrics=METRICS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-figure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = modeling.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler],\n",
    "    epochs=epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-council",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['precision']\n",
    "val_acc = history.history['val_precision']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_precision']\n",
    "\n",
    "epochs_range = range(epoch)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-material",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "        tf.keras.Input(shape=(*image_size, 3)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPool2D(),\n",
    "        \n",
    "        conv_block(32),\n",
    "        conv_block(64),\n",
    "        \n",
    "        conv_block(128),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        conv_block(256),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        dense_block(200, 0.7),\n",
    "        dense_block(120, 0.5),\n",
    "        dense_block(64, 0.3),\n",
    "        \n",
    "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling = build_model()\n",
    "\n",
    "METRICS = [tf.keras.metrics.Precision(name='precision')]\n",
    "    \n",
    "modeling.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.losses.CategoricalCrossentropy(),\n",
    "        metrics=METRICS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = modeling.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler],\n",
    "    epochs=epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-device",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['precision']\n",
    "val_acc = history.history['val_precision']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_precision']\n",
    "\n",
    "epochs_range = range(epoch)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential([\n",
    "    Conv2D(filters=32,kernel_size=3,activation='relu',input_shape = image_size),\n",
    "    MaxPooling2D(pool_size=2) ,# down sampling the output instead of 28*28 it is 14*14\n",
    "    Dropout(0.2),\n",
    "    Flatten(), # flatten out the layers\n",
    "    Dense(32,activation='relu'),\n",
    "    Dense(10,activation = 'softmax')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    tf.keras.Input(shape=(*image_size, 3)),\n",
    "    tf.keras.layers.Flatten(input_shape=(64,64)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy'])\n",
    "\n",
    "simple = model.fit(train_data, validation_data=val_data, epochs=epoch)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(train_data)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-mirror",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_size, n_categories):\n",
    "    \"\"\"\n",
    "    Create a simple baseline CNN\n",
    "    Args:\n",
    "        input_size (tuple(int, int, int)): 3-dimensional size of input to model\n",
    "        n_categories (int): number of classification categories\n",
    "    Returns:\n",
    "        keras Sequential model: model with new head\n",
    "        \"\"\"\n",
    "\n",
    "    nb_filters = 32\n",
    "    kernel_size = (3, 3)\n",
    "    pool_size = (2, 2)\n",
    "\n",
    "    model = Sequential()\n",
    "    # 2 convolutional layers followed by a pooling layer followed by dropout\n",
    "    model.add(Convolution2D(nb_filters, kernel_size,\n",
    "                            padding='valid',\n",
    "                            input_shape=input_size))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(nb_filters, kernel_size))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.25))\n",
    "    # transition to an mlp\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_categories))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple = create_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-ultimate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-mountain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-removal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-professor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-raleigh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-contemporary",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(, 3)))  # 250x250 RGB images\n",
    "model.add(layers.Conv2D(32, 5, strides=2, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "# Can you guess what the current output shape is at this point? Probably not.\n",
    "# Let's just print it:\n",
    "model.summary()\n",
    "\n",
    "# The answer was: (40, 40, 32), so we can keep downsampling...\n",
    "\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "# And now?\n",
    "model.summary()\n",
    "\n",
    "# Now that we have 4x4 feature maps, time to apply global max pooling.\n",
    "model.add(layers.GlobalMaxPooling2D())\n",
    "\n",
    "# Finally, we add a classification layer.\n",
    "model.add(layers.Dense(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
